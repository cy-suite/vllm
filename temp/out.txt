INFO 04-18 20:24:58 pynccl.py:58] Loading nccl from library /root/.config/vllm/nccl/cu12/libnccl.so.2.18.1
INFO 04-18 20:24:59 llm_engine.py:81] Initializing an LLM engine (v0.4.0.post1) with config: model='lmsys/vicuna-7b-v1.5', speculative_config=None, tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, seed=0)
INFO 04-18 20:24:59 selector.py:77] Cannot use FlashAttention backend because the flash_attn package is not found. Please install it for better performance.
INFO 04-18 20:24:59 selector.py:33] Using XFormers backend.
INFO 04-18 20:25:01 weight_utils.py:194] Using model weights format ['*.bin']
INFO 04-18 20:25:09 model_runner.py:164] Loading model weights took 12.5523 GB
	execute_model: tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0'), tensor([ 0,  1,  2,  ..., 13, 14, 15], device='cuda:0')
INFO 04-18 20:25:10 gpu_executor.py:81] # GPU blocks: 3402, # CPU blocks: 512
max model len 4096
	execute_model: tensor([    1,  2266,   338,  ...,   363,   592, 29973], device='cuda:0'), tensor([   0,    1,    2,  ..., 4065, 4066, 4067], device='cuda:0')
		FREE BLOCKS 3147
INFO 04-18 20:25:12 metrics.py:224] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.5%, CPU KV cache usage: 0.0%
	execute_model: tensor([13], device='cuda:0'), tensor([4068], device='cuda:0')
		FREE BLOCKS 3147
	execute_model: tensor([13], device='cuda:0'), tensor([4069], device='cuda:0')
		FREE BLOCKS 3147
	execute_model: tensor([4013], device='cuda:0'), tensor([4070], device='cuda:0')
		FREE BLOCKS 3147
	execute_model: tensor([5650], device='cuda:0'), tensor([4071], device='cuda:0')
		FREE BLOCKS 3147
	execute_model: tensor([16612], device='cuda:0'), tensor([4072], device='cuda:0')
		FREE BLOCKS 3147
	execute_model: tensor([278], device='cuda:0'), tensor([4073], device='cuda:0')
		FREE BLOCKS 3147
	execute_model: tensor([349], device='cuda:0'), tensor([4074], device='cuda:0')
		FREE BLOCKS 3147
	execute_model: tensor([1165], device='cuda:0'), tensor([4075], device='cuda:0')
		FREE BLOCKS 3147
	execute_model: tensor([359], device='cuda:0'), tensor([4076], device='cuda:0')
		FREE BLOCKS 3147
	execute_model: tensor([5687], device='cuda:0'), tensor([4077], device='cuda:0')
		FREE BLOCKS 3147
	execute_model: tensor([363], device='cuda:0'), tensor([4078], device='cuda:0')
		FREE BLOCKS 3147
	execute_model: tensor([3657], device='cuda:0'), tensor([4079], device='cuda:0')
		FREE BLOCKS 3147
	execute_model: tensor([15387], device='cuda:0'), tensor([4080], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([1136], device='cuda:0'), tensor([4081], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([8841], device='cuda:0'), tensor([4082], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([297], device='cuda:0'), tensor([4083], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([263], device='cuda:0'), tensor([4084], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([13235], device='cuda:0'), tensor([4085], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([1788], device='cuda:0'), tensor([4086], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([29889], device='cuda:0'), tensor([4087], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([450], device='cuda:0'), tensor([4088], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([5687], device='cuda:0'), tensor([4089], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([3913], device='cuda:0'), tensor([4090], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([263], device='cuda:0'), tensor([4091], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([9551], device='cuda:0'), tensor([4092], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([261], device='cuda:0'), tensor([4093], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([29892], device='cuda:0'), tensor([4094], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([3544], device='cuda:0'), tensor([4095], device='cuda:0')
		FREE BLOCKS 3146
	execute_model: tensor([943], device='cuda:0'), tensor([4096], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([3544], device='cuda:0'), tensor([4097], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([943], device='cuda:0'), tensor([4098], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([29892], device='cuda:0'), tensor([4099], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([322], device='cuda:0'), tensor([4100], device='cuda:0')
		FREE BLOCKS 3145
INFO 04-18 20:25:18 metrics.py:224] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%
	execute_model: tensor([24298], device='cuda:0'), tensor([4101], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([1089], device='cuda:0'), tensor([4102], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([10174], device='cuda:0'), tensor([4103], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([393], device='cuda:0'), tensor([4104], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([29892], device='cuda:0'), tensor([4105], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([322], device='cuda:0'), tensor([4106], device='cuda:0')
		FREE BLOCKS 3145
INFO 04-18 20:25:23 metrics.py:224] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%
	execute_model: tensor([24298], device='cuda:0'), tensor([4107], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([1089], device='cuda:0'), tensor([4108], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([29892], device='cuda:0'), tensor([4109], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([322], device='cuda:0'), tensor([4110], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([24298], device='cuda:0'), tensor([4111], device='cuda:0')
		FREE BLOCKS 3145
	execute_model: tensor([1089], device='cuda:0'), tensor([4112], device='cuda:0')
		FREE BLOCKS 3144
INFO 04-18 20:25:29 metrics.py:224] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%
	execute_model: tensor([29892], device='cuda:0'), tensor([4113], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([322], device='cuda:0'), tensor([4114], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([24298], device='cuda:0'), tensor([4115], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([1089], device='cuda:0'), tensor([4116], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([3544], device='cuda:0'), tensor([4117], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([943], device='cuda:0'), tensor([4118], device='cuda:0')
		FREE BLOCKS 3144
INFO 04-18 20:25:34 metrics.py:224] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%
	execute_model: tensor([29892], device='cuda:0'), tensor([4119], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([322], device='cuda:0'), tensor([4120], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([24298], device='cuda:0'), tensor([4121], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([1089], device='cuda:0'), tensor([4122], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([29892], device='cuda:0'), tensor([4123], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([322], device='cuda:0'), tensor([4124], device='cuda:0')
		FREE BLOCKS 3144
INFO 04-18 20:25:40 metrics.py:224] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%
	execute_model: tensor([24298], device='cuda:0'), tensor([4125], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([1089], device='cuda:0'), tensor([4126], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([3544], device='cuda:0'), tensor([4127], device='cuda:0')
		FREE BLOCKS 3144
	execute_model: tensor([943], device='cuda:0'), tensor([4128], device='cuda:0')
		FREE BLOCKS 3143
	execute_model: tensor([29892], device='cuda:0'), tensor([4129], device='cuda:0')
		FREE BLOCKS 3143
	execute_model: tensor([322], device='cuda:0'), tensor([4130], device='cuda:0')
		FREE BLOCKS 3143
INFO 04-18 20:25:45 metrics.py:224] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%
	execute_model: tensor([5110], device='cuda:0'), tensor([4131], device='cuda:0')
		FREE BLOCKS 3143
	execute_model: tensor([414], device='cuda:0'), tensor([4132], device='cuda:0')
		FREE BLOCKS 3143
	execute_model: tensor([29892], device='cuda:0'), tensor([4133], device='cuda:0')
		FREE BLOCKS 3143
	execute_model: tensor([322], device='cuda:0'), tensor([4134], device='cuda:0')
		FREE BLOCKS 3143
	execute_model: tensor([24298], device='cuda:0'), tensor([4135], device='cuda:0')
		FREE BLOCKS 3143
	execute_model: tensor([1089], device='cuda:0'), tensor([4136], device='cuda:0')
		FREE BLOCKS 3143
INFO 04-18 20:25:51 metrics.py:224] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 7.6%, CPU KV cache usage: 0.0%
	execute_model: tensor([29889], device='cuda:0'), tensor([4137], device='cuda:0')
		FREE BLOCKS 3143

OUTPUT: (71 tokens)


This paper describes the Paxos algorithm for achieving consensus in a distributed system. The algorithm uses a proposer, acceptors acceptors, and learner processes that, and learner, and learner, and learner acceptors, and learner, and learner acceptors, and learners, and learner. 

[CompletionOutput(index=0, text='\n\nThis paper describes the Paxos algorithm for achieving consensus in a distributed system. The algorithm uses a proposer, acceptors acceptors, and learner processes that, and learner, and learner, and learner acceptors, and learner, and learner acceptors, and learners, and learner.', token_ids=[13, 13, 4013, 5650, 16612, 278, 349, 1165, 359, 5687, 363, 3657, 15387, 1136, 8841, 297, 263, 13235, 1788, 29889, 450, 5687, 3913, 263, 9551, 261, 29892, 3544, 943, 3544, 943, 29892, 322, 24298, 1089, 10174, 393, 29892, 322, 24298, 1089, 29892, 322, 24298, 1089, 29892, 322, 24298, 1089, 3544, 943, 29892, 322, 24298, 1089, 29892, 322, 24298, 1089, 3544, 943, 29892, 322, 5110, 414, 29892, 322, 24298, 1089, 29889, 2], cumulative_logprob=-25.970335724071873, logprobs=None, finish_reason=stop, stop_reason=None)]
