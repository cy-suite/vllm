import itertools
from typing import Dict, List, Tuple

import pytest

TokensText = Tuple[List[int], str]


def check_outputs_equal(
    *,
    outputs_0_lst: List[TokensText],
    outputs_1_lst: List[TokensText],
    name_0: str,
    name_1: str,
):
    """
    Compare the two sequences generated by different models, 
    which should be equal.
    """
    assert len(outputs_0_lst) == len(outputs_1_lst)

    for prompt_idx, (outputs_0,
                     outputs_1) in enumerate(zip(outputs_0_lst,
                                                 outputs_1_lst)):
        output_ids_0, output_str_0 = outputs_0
        output_ids_1, output_str_1 = outputs_1

        assert output_str_0 == output_str_1, (f"Test{prompt_idx}:"
                                              f"\n{name_0}:\t{output_str_0!r}"
                                              f"\n{name_1}:\t{output_str_1!r}")
        assert output_ids_0 == output_ids_1, (f"Test{prompt_idx}:"
                                              f"\n{name_0}:\t{output_str_0!r}"
                                              f"\n{name_1}:\t{output_str_1!r}")


def check_outputs_equal_xfail(
    *,
    outputs_0_lst: List[TokensText],
    outputs_1_lst: List[TokensText],
    outputs_num_prefix_tokens: List[int],
    name_0: str,
    name_1: str,
    min_tokens_to_xfail: int,
    min_tokens_to_pass: int,
):
    """
    Compare the two sequences generated by different models, 
    which should be equal, but we xfail instead of completely failing
    the test if the outputs are equal up to a certain number of
    `min_tokens_to_xfail` after omitting the first `num_prefix_tokens`.
    """
    assert len(outputs_0_lst) == len(outputs_1_lst)
    assert len(outputs_0_lst) == len(outputs_num_prefix_tokens)

    num_tokens_to_pass_exc_list: List[Tuple[int, AssertionError]] = []
    for prompt_idx, (outputs_0, outputs_1, num_prefix_tokens) in enumerate(
            zip(outputs_0_lst, outputs_1_lst, outputs_num_prefix_tokens)):

        output_ids_0, output_str_0 = outputs_0
        output_ids_1, output_str_1 = outputs_1

        try:
            assert output_str_0 == output_str_1, (
                f"Test{prompt_idx}:"
                f"\n{name_0}:\t{output_str_0!r}"
                f"\n{name_1}:\t{output_str_1!r}")
            assert output_ids_0 == output_ids_1, (
                f"Test{prompt_idx}:"
                f"\n{name_0}:\t{output_str_0!r}"
                f"\n{name_1}:\t{output_str_1!r}")
        except AssertionError as e:
            num_tokens_to_pass = sum(1 for _ in itertools.takewhile(
                lambda pair: pair[0] == pair[1],
                zip(output_ids_0[num_prefix_tokens:],
                    output_ids_1[num_prefix_tokens:]),
            ))

            assert num_tokens_to_pass < min_tokens_to_pass, (
                "The original assertion should pass")

            if num_tokens_to_pass < min_tokens_to_xfail:
                raise

            num_tokens_to_pass_exc_list.append((num_tokens_to_pass, e))

    if num_tokens_to_pass_exc_list:
        num_tokens_to_pass = min(pair[0]
                                 for pair in num_tokens_to_pass_exc_list)
        exc_list = [pair[1] for pair in num_tokens_to_pass_exc_list]

        pytest.xfail(
            f"Test only fully passes when max_tokens={num_tokens_to_pass} "
            f"(instead of {min_tokens_to_pass}). "
            f"Errors encountered per item: {exc_list}")


TokensTextLogprobs = Tuple[List[int], str, List[Dict[int, float]]]


def check_logprobs_close(
    *,
    outputs_0_lst: List[TokensTextLogprobs],
    outputs_1_lst: List[TokensTextLogprobs],
    name_0: str,
    name_1: str,
):
    """
    Compare the logprobs of two sequences generated by different models,
    which should be similar but not necessarily equal.
    """
    assert len(outputs_0_lst) == len(outputs_1_lst)

    # Loop through responses to each prompt.
    for prompt_idx, (outputs_0,
                     outputs_1) in enumerate(zip(outputs_0_lst,
                                                 outputs_1_lst)):
        output_ids_0, output_str_0, logprobs_0 = outputs_0
        output_ids_1, output_str_1, logprobs_1 = outputs_1

        # Loop through generated tokens.
        for idx, (output_id_0,
                  output_id_1) in enumerate(zip(output_ids_0, output_ids_1)):

            # If generated tokens don't match, then
            if output_id_0 != output_id_1:
                # Each predicted token must be in top N logprobs of the other
                assert output_id_0 in logprobs_1[idx], (
                    f"Test{prompt_idx}:"
                    f"\n{name_0}:\t{output_str_0!r}"
                    f"\n{name_1}:\t{output_str_1!r}")
                assert output_id_1 in logprobs_0[idx], (
                    f"Test{prompt_idx}:"
                    f"\n{name_0}:\t{output_str_0!r}"
                    f"\n{name_1}:\t{output_str_1!r}")

                # Break out since sequences will now diverge.
                break
