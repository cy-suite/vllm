steps:
  # NOTE(simon): You can create separate blocks for different jobs
  - label: "A100: NVIDIA SMI"
    agents:
      queue: A100
    plugins:
    - kubernetes:
        podSpec:
          containers:
          # - image: us-central1-docker.pkg.dev/vllm-405802/vllm-ci-test-repo/vllm-test:$BUILDKITE_COMMIT
          # TODO(simon): check latest main branch or use the PR image.
          - image: us-central1-docker.pkg.dev/vllm-405802/vllm-ci-test-repo/vllm-test:f7f9c5f97b4dd206a3cd9c65729a1c807ac82f50
            command:
            - bash .buildkite/nightly-benchmarks/run-vllm-benchmarks.sh
            resources:
              limits:
                nvidia.com/gpu: 8
            volumeMounts:
            - name: devshm
              mountPath: /dev/shm
            env:
            - name: VLLM_USAGE_SOURCE
              value: ci-test
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token-secret
                  key: token
          nodeSelector:
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          volumes:
          - name: devshm
            emptyDir:
              medium: Memory
  - label: "H100: NVIDIA SMI"
    agents:
      queue: H100
    plugins:
    - docker#v5.11.0:
        image: us-central1-docker.pkg.dev/vllm-405802/vllm-ci-test-repo/vllm-test:f7f9c5f97b4dd206a3cd9c65729a1c807ac82f50
        command:
        - bash .buildkite/nightly-benchmarks/run-vllm-benchmarks.sh
        propagate-environment: true
        ipc: host
        gpus: all

