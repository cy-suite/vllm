





steps:
  - label: ":docker: build image"
    key: image-build
    agents:
      queue: cpu_queue
    commands:
      - "aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws/q9t5s3a7"
      - |
        #!/bin/bash
        if [[ -z $(docker manifest inspect public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT) ]]; then
          echo "Image not found, proceeding with build..."
        else
          echo "Image found"
          exit 0
        fi
      - "docker build --build-arg max_jobs=16 --build-arg buildkite_commit=$BUILDKITE_COMMIT --build-arg USE_SCCACHE=1 --tag public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT --target test --progress plain ."
      - "docker push public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT"
    env:
      DOCKER_BUILDKIT: "1"
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 5
        - exit_status: -10  # Agent was lost
          limit: 5

  - group: "AMD Tests"
    steps:
      - label: "AMD: :docker: build image"
        depends_on: ~
        commands:
          - "docker build --build-arg max_jobs=16 --tag rocmshared/vllm-ci:$BUILDKITE_COMMIT -f Dockerfile.rocm --progress plain ."
          - "docker push rocmshared/vllm-ci:$BUILDKITE_COMMIT"
        plugins:
          - docker-login#v3.0.0:
              username: rocmshared
        key: "amd-build"
        env:
          DOCKER_BUILDKIT: "1"
        retry:
          automatic:
            - exit_status: -1  # Agent was lost
              limit: 5
            - exit_status: -10  # Agent was lost
              limit: 5
        agents:
          queue: amd-cpu

    
    
    
    
    
    
      - label: "AMD: Regression Test"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/tests ; pytest -v -s test_regression.py"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
    
    
      - label: "AMD: Basic Correctness Test"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/tests ; pip install https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.8/flashinfer-0.0.8+cu121torch2.3-cp310-cp310-linux_x86_64.whl || true && pytest -v -s basic_correctness/test_basic_correctness.py && pytest -v -s basic_correctness/test_cpu_offload.py && VLLM_ATTENTION_BACKEND=XFORMERS pytest -v -s basic_correctness/test_chunked_prefill.py && VLLM_ATTENTION_BACKEND=FLASH_ATTN pytest -v -s basic_correctness/test_chunked_prefill.py && VLLM_TEST_ENABLE_ARTIFICIAL_PREEMPT=1 pytest -v -s basic_correctness/test_preemption.py"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
      - label: "AMD: Core Test"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/tests ; pytest -v -s core"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
    
    
    
    
      - label: "AMD: Distributed Tests (2 GPUs)"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/tests ; VLLM_TEST_SAME_HOST=1 torchrun --nproc-per-node=4 distributed/test_same_node.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=meta-llama/Llama-2-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=ray VLLM_USE_RAY_SPMD_WORKER=1 VLLM_USE_RAY_COMPILED_DAG=1 pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=meta-llama/Llama-2-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=ray VLLM_USE_RAY_SPMD_WORKER=1 VLLM_USE_RAY_COMPILED_DAG=1 pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_chunked_prefill_distributed.py && TEST_DIST_MODEL=meta-llama/Llama-2-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_chunked_prefill_distributed.py && TEST_DIST_MODEL=llava-hf/llava-1.5-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_multimodal_broadcast.py && TEST_DIST_MODEL=llava-hf/llava-v1.6-mistral-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_multimodal_broadcast.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=meta-llama/Llama-2-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_chunked_prefill_distributed.py && TEST_DIST_MODEL=meta-llama/Llama-2-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_chunked_prefill_distributed.py && TEST_DIST_MODEL=llava-hf/llava-1.5-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_multimodal_broadcast.py && TEST_DIST_MODEL=llava-hf/llava-v1.6-mistral-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_multimodal_broadcast.py && pytest -v -s spec_decode/e2e/test_integration_dist_tp2.py && CUDA_VISIBLE_DEVICES=0,1 pytest -v -s test_sharded_state_loader.py && CUDA_VISIBLE_DEVICES=0,1 pytest -v -s distributed/test_utils.py"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
    
    
    
    
      - label: "AMD: Engine Test"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/tests ; pytest -v -s engine test_sequence.py test_config.py test_logger.py && pytest -v -s tokenization"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
      - label: "AMD: Entrypoints Test"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/tests ; pytest -v -s entrypoints/llm && pytest -v -s entrypoints/openai"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
      - label: "AMD: Examples Test"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/examples ; pip install awscli tensorizer && python3 offline_inference.py && python3 cpu_offload.py && python3 offline_inference_with_prefix.py && python3 llm_engine_example.py && python3 offline_inference_vision_language.py && python3 tensorize_vllm_model.py --model facebook/opt-125m serialize --serialized-directory /tmp/ --suffix v1 && python3 tensorize_vllm_model.py --model facebook/opt-125m deserialize --path-to-tensors /tmp/vllm/facebook/opt-125m/v1/model.tensors"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
    
    
    
    
      - label: "AMD: Vision Language Models Test"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/tests ; pytest -v -s models -m vlm"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
      - label: "AMD: Prefix Caching Test"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/tests ; pytest -v -s prefix_caching"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
    
    
      - label: "AMD: LogitsProcessor Test"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/tests ; pytest -v -s test_logits_processor.py"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
    
    
      - label: "AMD: Worker Test"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/tests ; pytest -v -s worker"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
    
    
    
    
      - label: "AMD: Metrics Test"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/tests ; pytest -v -s metrics"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
    
    
    
    
      - label: "AMD: Benchmarks"
        depends_on: 
          - "amd-build"
        agents:
          queue: amd
        command: bash .buildkite/run-amd-test.sh "cd /vllm-workspace/.buildkite ; pip install aiohttp && bash run-benchmarks.sh"
        env:
          DOCKER_BUILDKIT: "1"
        priority: 100
        soft_fail: true
    
    
    
    
    
    
    
    
    
    

  - label: "Neuron Test"
    depends_on: ~
    agents:
      queue: neuron
    command: bash .buildkite/run-neuron-test.sh
    soft_fail: false

  - label: "Intel CPU Test"
    depends_on: ~
    agents:
      queue: intel-cpu
    command: bash .buildkite/run-cpu-test.sh

  - label: "Intel GPU Test"
    soft_fail: true
    agents:
      queue: intel-gpu
    command: bash .buildkite/run-xpu-test.sh
  
  

  
  

  

  

  
  - block: "Run Async Engine, Inputs, Utils, Worker Test"
    depends_on: image_build
    key: block-async-engine--inputs--utils--worker-test
  

  - label: "Async Engine, Inputs, Utils, Worker Test"
    
    depends_on: block-async-engine--inputs--utils--worker-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s async_engine && pytest -v -s test_inputs.py && pytest -v -s multimodal && pytest -v -s test_utils.py && pytest -v -s worker"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Metrics, Tracing Test"
    depends_on: image_build
    key: block-metrics--tracing-test
  

  - label: "Metrics, Tracing Test"
    
    depends_on: block-metrics--tracing-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s metrics && pip install opentelemetry-sdk opentelemetry-api opentelemetry-exporter-otlp opentelemetry-semantic-conventions-ai && pytest -v -s tracing"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Regression Test"
    depends_on: image_build
    key: block-regression-test
  

  - label: "Regression Test"
    
    depends_on: block-regression-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s test_regression.py"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run AsyncEngine Test"
    depends_on: image_build
    key: block-asyncengine-test
  

  - label: "AsyncEngine Test"
    
    depends_on: block-asyncengine-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s async_engine"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Basic Correctness Test"
    depends_on: image_build
    key: block-basic-correctness-test
  

  - label: "Basic Correctness Test"
    
    depends_on: block-basic-correctness-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pip install https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.8/flashinfer-0.0.8+cu121torch2.3-cp310-cp310-linux_x86_64.whl || true && pytest -v -s basic_correctness/test_basic_correctness.py && pytest -v -s basic_correctness/test_cpu_offload.py && VLLM_ATTENTION_BACKEND=XFORMERS pytest -v -s basic_correctness/test_chunked_prefill.py && VLLM_ATTENTION_BACKEND=FLASH_ATTN pytest -v -s basic_correctness/test_chunked_prefill.py && VLLM_TEST_ENABLE_ARTIFICIAL_PREEMPT=1 pytest -v -s basic_correctness/test_preemption.py"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Core Test"
    depends_on: image_build
    key: block-core-test
  

  - label: "Core Test"
    
    depends_on: block-core-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s core"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Distributed Comm Ops Test"
    depends_on: image_build
    key: block-distributed-comm-ops-test
  

  - label: "Distributed Comm Ops Test"
    
    depends_on: block-distributed-comm-ops-test
    
    agents:
      
      queue: gpu_4_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s distributed/test_comm_ops.py && pytest -v -s distributed/test_shm_broadcast.py"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run 2 Node Tests (4 GPUs in total)"
    depends_on: image_build
    key: block-2-node-tests-4-gpus-in-total
  

  - label: "2 Node Tests (4 GPUs in total)"
    
    depends_on: block-2-node-tests-4-gpus-in-total
    
    agents:
      
      queue: gpu_4_queue
      
     
    commands:
      - ./.buildkite/run-multi-node-test.sh /vllm-workspace/tests 2 2 public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT "VLLM_TEST_SAME_HOST=0 torchrun --nnodes 2 --nproc-per-node=2 --rdzv_backend=c10d --rdzv_endpoint=192.168.10.10 distributed/test_same_node.py && VLLM_MULTI_NODE=1 pytest -v -s distributed/test_pipeline_parallel.py" "VLLM_TEST_SAME_HOST=0 torchrun --nnodes 2 --nproc-per-node=2 --rdzv_backend=c10d --rdzv_endpoint=192.168.10.10 distributed/test_same_node.py" 
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
  

  
  

  

  

  
  - block: "Run Distributed Tests (2 GPUs)"
    depends_on: image_build
    key: block-distributed-tests-2-gpus
  

  - label: "Distributed Tests (2 GPUs)"
    
    depends_on: block-distributed-tests-2-gpus
    
    agents:
      
      queue: gpu_4_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && VLLM_TEST_SAME_HOST=1 torchrun --nproc-per-node=4 distributed/test_same_node.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=meta-llama/Llama-2-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=ray VLLM_USE_RAY_SPMD_WORKER=1 VLLM_USE_RAY_COMPILED_DAG=1 pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=meta-llama/Llama-2-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=ray VLLM_USE_RAY_SPMD_WORKER=1 VLLM_USE_RAY_COMPILED_DAG=1 pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_chunked_prefill_distributed.py && TEST_DIST_MODEL=meta-llama/Llama-2-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_chunked_prefill_distributed.py && TEST_DIST_MODEL=llava-hf/llava-1.5-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_multimodal_broadcast.py && TEST_DIST_MODEL=llava-hf/llava-v1.6-mistral-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_multimodal_broadcast.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=meta-llama/Llama-2-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_chunked_prefill_distributed.py && TEST_DIST_MODEL=meta-llama/Llama-2-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_chunked_prefill_distributed.py && TEST_DIST_MODEL=llava-hf/llava-1.5-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_multimodal_broadcast.py && TEST_DIST_MODEL=llava-hf/llava-v1.6-mistral-7b-hf DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_multimodal_broadcast.py && pytest -v -s spec_decode/e2e/test_integration_dist_tp2.py && CUDA_VISIBLE_DEVICES=0,1 pytest -v -s test_sharded_state_loader.py && CUDA_VISIBLE_DEVICES=0,1 pytest -v -s distributed/test_utils.py"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Distributed Tests (4 GPUs)"
    depends_on: image_build
    key: block-distributed-tests-4-gpus
  

  - label: "Distributed Tests (4 GPUs)"
    
    depends_on: block-distributed-tests-4-gpus
    
    agents:
      
      queue: gpu_4_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s distributed/test_pynccl.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=ray VLLM_USE_RAY_SPMD_WORKER=1 VLLM_USE_RAY_COMPILED_DAG=1 pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_basic_distributed_correctness.py && pytest -v -s spec_decode/e2e/test_integration_dist_tp4.py"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Pipeline Parallelism Test"
    depends_on: image_build
    key: block-pipeline-parallelism-test
  

  - label: "Pipeline Parallelism Test"
    
    depends_on: block-pipeline-parallelism-test
    
    agents:
      
      queue: gpu_4_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s distributed/test_pipeline_parallel.py"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Engine Test"
    depends_on: image_build
    key: block-engine-test
  

  - label: "Engine Test"
    
    depends_on: block-engine-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s engine test_sequence.py test_config.py test_logger.py && pytest -v -s tokenization"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Entrypoints Test"
    depends_on: image_build
    key: block-entrypoints-test
  

  - label: "Entrypoints Test"
    
    depends_on: block-entrypoints-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s entrypoints/llm && pytest -v -s entrypoints/openai"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  
    
      
        
      
        
      
        
      
        
      
    
  

  

  
  - block: "Run Examples Test"
    depends_on: image_build
    key: block-examples-test
  

  - label: "Examples Test"
    
    depends_on: block-examples-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/examples && pip install awscli tensorizer && python3 offline_inference.py && python3 cpu_offload.py && python3 offline_inference_with_prefix.py && python3 llm_engine_example.py && python3 offline_inference_vision_language.py && python3 tensorize_vllm_model.py --model facebook/opt-125m serialize --serialized-directory /tmp/ --suffix v1 && python3 tensorize_vllm_model.py --model facebook/opt-125m deserialize --path-to-tensors /tmp/vllm/facebook/opt-125m/v1/model.tensors"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Inputs Test"
    depends_on: image_build
    key: block-inputs-test
  

  - label: "Inputs Test"
    
    depends_on: block-inputs-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s test_inputs.py && pytest -v -s multimodal"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Models Test"
    depends_on: image_build
    key: block-models-test
  

  - label: "Models Test"
    
    depends_on: block-models-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pip install https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.8/flashinfer-0.0.8+cu121torch2.3-cp310-cp310-linux_x86_64.whl && pytest -v -s models -m \"not vlm\""]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Vision Language Models Test"
    depends_on: image_build
    key: block-vision-language-models-test
  

  - label: "Vision Language Models Test"
    
    depends_on: block-vision-language-models-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s models -m vlm"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Prefix Caching Test"
    depends_on: image_build
    key: block-prefix-caching-test
  

  - label: "Prefix Caching Test"
    
    depends_on: block-prefix-caching-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s prefix_caching"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Samplers Test"
    depends_on: image_build
    key: block-samplers-test
  

  - label: "Samplers Test"
    
    depends_on: block-samplers-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s samplers"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run LogitsProcessor Test"
    depends_on: image_build
    key: block-logitsprocessor-test
  

  - label: "LogitsProcessor Test"
    
    depends_on: block-logitsprocessor-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s test_logits_processor.py"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Utils Test"
    depends_on: image_build
    key: block-utils-test
  

  - label: "Utils Test"
    
    depends_on: block-utils-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s test_utils.py && pytest -v -s test_embedded_commit.py"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Worker Test"
    depends_on: image_build
    key: block-worker-test
  

  - label: "Worker Test"
    
    depends_on: block-worker-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s worker"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Speculative decoding tests"
    depends_on: image_build
    key: block-speculative-decoding-tests
  

  - label: "Speculative decoding tests"
    
    depends_on: block-speculative-decoding-tests
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && export VLLM_ATTENTION_BACKEND=XFORMERS && pytest -v -s spec_decode"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
            - VLLM_ATTENTION_BACKEND=XFORMERS
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Tensorizer Test"
    depends_on: image_build
    key: block-tensorizer-test
  

  - label: "Tensorizer Test"
    
    depends_on: block-tensorizer-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && apt-get install -y curl libsodium23 && export VLLM_WORKER_MULTIPROC_METHOD=spawn && pytest -v -s tensorizer_loader"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Metrics Test"
    depends_on: image_build
    key: block-metrics-test
  

  - label: "Metrics Test"
    
    depends_on: block-metrics-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s metrics"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Quantization Test"
    depends_on: image_build
    key: block-quantization-test
  

  - label: "Quantization Test"
    
    depends_on: block-quantization-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pytest -v -s quantization"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Tracing Test"
    depends_on: image_build
    key: block-tracing-test
  

  - label: "Tracing Test"
    
    depends_on: block-tracing-test
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/tests && pip install opentelemetry-sdk opentelemetry-api opentelemetry-exporter-otlp opentelemetry-semantic-conventions-ai && pytest -v -s tracing"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run Benchmarks"
    depends_on: image_build
    key: block-benchmarks
  

  - label: "Benchmarks"
    
    depends_on: block-benchmarks
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          mount-buildkite-agent: true
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/.buildkite && pip install aiohttp && bash run-benchmarks.sh"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  

  
  - block: "Run LM Eval Small Models"
    depends_on: image_build
    key: block-lm-eval-small-models
  

  - label: "LM Eval Small Models"
    
    depends_on: block-lm-eval-small-models
    
    agents:
      
      queue: gpu_1_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          gpus: all
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/.buildkite/lm-eval-harness && pip install lm-eval && export VLLM_WORKER_MULTIPROC_METHOD=spawn && bash ./run-tests.sh -c configs/models-small.txt -t 1"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  
  
  

  
  - block: "Run LM Eval Large Models"
    depends_on: image_build
    key: block-lm-eval-large-models
  

  - label: "LM Eval Large Models"
    
    depends_on: block-lm-eval-large-models
    
    agents:
      
      queue: gpu_4_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
       
        - kubernetes:
        podSpec:
          priorityClassName: ci
          containers:
          - image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
            command: ["bash"]
            args:
            - '-c'
            - "'cd /vllm-workspace/.buildkite/lm-eval-harness && pip install lm-eval && export VLLM_WORKER_MULTIPROC_METHOD=spawn && bash ./run-tests.sh -c configs/models-large.txt -t 4'"
            resources:
              limits:
                nvidia.com/gpu: 4
            volumeMounts:
            - name: devshm
              mountPath: /dev/shm
            - name: hf-cache
              mountPath: /root/.cache/huggingface
            env:
            - name: VLLM_USAGE_SOURCE
              value: ci-test
            - name: HF_HOME
              value: /root/.cache/huggingface
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token-secret
                  key: token
          nodeSelector:
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          volumes:
          - name: devshm
            emptyDir:
              medium: Memory
          - name: hf-cache
            hostPath:
              path: /root/.cache/huggingface
              type: Directory
      
    
  

  
  

  

  

  
  - block: "Run Documentation Build"
    depends_on: image_build
    key: block-documentation-build
  

  - label: "Documentation Build"
    
    depends_on: block-documentation-build
    
    agents:
      
      queue: small_cpu_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
      
      - docker#v5.2.0: 
          image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
          always-pull: true
          propagate-environment: true
          
          
          command: ["bash", "-c", "(command nvidia-smi || true) && cd /vllm-workspace/test_docs/docs && pip install -r requirements-docs.txt && SPHINXOPTS=\"-W\" make html"]
          environment:
            - VLLM_USAGE_SOURCE=ci-test
            - HF_HOME=/root/.cache/huggingface
            - HF_TOKEN
            
          volumes:
            - /dev/shm:/dev/shm
            - /root/.cache/huggingface:/root/.cache/huggingface
      
    
  

  
  

  

  
  
  

  
  - block: "Run Distributed Tests (A100)"
    depends_on: image_build
    key: block-distributed-tests-a100
  

  - label: "Distributed Tests (A100)"
    
    depends_on: block-distributed-tests-a100
    
    agents:
      
      queue: gpu_4_queue
      
    
    soft_fail: false
    
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2
    
    plugins:
       
        - kubernetes:
        podSpec:
          priorityClassName: ci
          containers:
          - image: public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT
            command: ["bash"]
            args:
            - '-c'
            - "'cd /vllm-workspace/tests && pytest -v -s distributed/test_custom_all_reduce.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_basic_distributed_correctness.py && TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=mp pytest -v -s distributed/test_basic_distributed_correctness.py && pip install https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.8/flashinfer-0.0.8+cu121torch2.3-cp310-cp310-linux_x86_64.whl && VLLM_ATTENTION_BACKEND=FLASHINFER TEST_DIST_MODEL=facebook/opt-125m DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_basic_distributed_correctness.py && VLLM_ATTENTION_BACKEND=FLASHINFER TEST_DIST_MODEL=meta-llama/Meta-Llama-3-8B DISTRIBUTED_EXECUTOR_BACKEND=ray pytest -v -s distributed/test_basic_distributed_correctness.py && pytest -v -s -x lora/test_mixtral.py'"
            resources:
              limits:
                nvidia.com/gpu: 4
            volumeMounts:
            - name: devshm
              mountPath: /dev/shm
            - name: hf-cache
              mountPath: /root/.cache/huggingface
            env:
            - name: VLLM_USAGE_SOURCE
              value: ci-test
            - name: HF_HOME
              value: /root/.cache/huggingface
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token-secret
                  key: token
          nodeSelector:
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          volumes:
          - name: devshm
            emptyDir:
              medium: Memory
          - name: hf-cache
            hostPath:
              path: /root/.cache/huggingface
              type: Directory
      
    
  
