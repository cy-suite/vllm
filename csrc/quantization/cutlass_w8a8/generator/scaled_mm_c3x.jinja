#include <stddef.h>
#include <torch/all.h>
#include "cutlass/cutlass.h"
#include "quantization/cutlass_w8a8/scaled_mm_c3x.cuh"

void {{ _name }}(torch::Tensor &out, torch::Tensor const &a,
                torch::Tensor const &b,
                torch::Tensor const &a_scales,
                torch::Tensor const &b_scales) {

  using TileShape =  {{ _tile_shape }};
  using ClusterShape = {{ _cluster_shape }};
  using KernelSchedule = typename {{ _kernel_schedule }};
  using EpilogueSchedule = typename {{ _epilogue_schedule }};
  using TileSchedule = typename {{ _tile_schedule }};
  using AccType = {{ _acc_type }};
  static constexpr cutlass::gemm::GemmUniversalMode Mode = {{ _gemm_mode }};

  TORCH_CHECK(a.dtype() == {{ _torch_input_dtype }});
  TORCH_CHECK(b.dtype() == {{ _torch_input_dtype}});
  TORCH_CHECK(a_scales.dtype() == torch::kFloat32);
  TORCH_CHECK(b_scales.dtype() == torch::kFloat32);

  if (out.dtype() == torch::kBFloat16) {
    using Cutlass3xGemm =
      cutlass_3x_gemm<{{ _cutlass_input_dtype }},
                      cutlass::bfloat16_t,
                      ScaledEpilogue,
                      TileShape,
                      ClusterShape,
                      KernelSchedule,
                      EpilogueSchedule,
                      AccType,
                      TileSchedule,
                      Mode>;

    return cutlass_gemm_caller<Cutlass3xGemm>(
        out, a, b, a_scales, b_scales);
  } else {
    TORCH_CHECK(out.dtype() == torch::kFloat16);
    using Cutlass3xGemm =
      cutlass_3x_gemm<{{ _cutlass_input_dtype }},
                      cutlass::half_t,
                      ScaledEpilogue,
                      TileShape,
                      ClusterShape,
                      KernelSchedule,
                      EpilogueSchedule,
                      AccType,
                      TileSchedule,
                      Mode>;

    return cutlass_gemm_caller<Cutlass3xGemm>(
        out, a, b, a_scales, b_scales);
  }
}
